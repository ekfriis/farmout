#!/bin/bash
#
# Setup:

#
# Usage:
#       farmoutAnalysisJobs <jobName> <CMSSW Version> <config file>
#
# The config file should refer to the following macros, which are automatically
# inserted by this script:
#
# $inputFileName      ==>  Will be replaced by one of the files in the dataset location
# $outputFileName     ==>  Will be replaced by the $inputFileName-output.root
#
# Job parameters
#


# Initialize default settings:

PNFS_HOME=/pnfs/hep.wisc.edu/data5/uscms01/$USER
SRM_SERVER=srm://cmssrm.hep.wisc.edu:8443
DCAP_SERVER=dcap://cmsdcap.hep.wisc.edu:22125
SRM_HOME=${SRM_SERVER}/${PNFS_HOME}
DCAP_HOME=${DCAP_SERVER}${PNFS_HOME}

scratch_dir="/data"
if ! [ -d $scratch_dir ]; then
  scratch_dir="/scratch"
fi
if ! [ -d $scratch_dir ]; then
  scratch_dir="/tmp"
fi
SUBMIT_HOME=${scratch_dir}/$USER

basename() {
  # This shell function is faster than calling /bin/basename
  path=$1
  suffix=$2
  path=${path##*/}  # get everything after the final '/'
  if [ ! -z $suffix ]; then
    path=${path%$suffix}
  fi
  echo $path
}

die() {
  echo 2>&1 $1
  exit 1
}

outputFileExists() {
  fname=$1

  #Strip off srm://hostname:8443 to get raw pnfs path.
  local_fname=${fname#srm://*:8443}

  echo "Local file name: $local_fname"
  if [ -f "$local_fname" ]; then
    return 0
  fi
  return 1
}

PrintUsage() {
  echo "USAGE: farmoutAnalysisJobs [options] <jobName> <CMSSW Version> <config file>"
  echo ""
  echo "OPTIONS:"
  echo "  --output-dir=${SRM_HOME}/<jobName>-<runName>"
  echo "  --input-dir=${DCAP_HOME}/<jobName>"
  echo "  --submit-dir=${SUBMIT_HOME}/<jobName>-<runName>"
  echo "  --no-submit"
  echo "  --job-count=N           (limit the number of jobs that are created)"
  echo "  --skip-existing-output  (do not create jobs if output file exists)"
  echo "  --skip-existing-jobs    (do not create jobs if job already created)"
  echo ""
  echo "Note that <runName> is taken from the name of the config file."
  exit 2
}

OPTS=`getopt -o "h" -l "help,output-dir:,input-dir:,submit-dir:,no-submit,job-count:,skip-existing-output,skip-existing-jobs" -- "$@"`
if [ $? -ne 0 ]; then PrintUsage; fi

eval set -- "$OPTS"

NO_SUBMIT=
JOB_LIMIT=
SKIP_EXISTING_OUTPUT=
SKIP_EXISTING_JOBS=
OUTPUT_DIR=
INPUT_DIR=
SUBMIT_DIR=

while [ ! -z "$1" ]
do
  case "$1" in
    -h) PrintUsage;;
    --help) PrintUsage;;
    --no-submit) NO_SUBMIT=1;;
    --job-count) shift; JOB_LIMIT=$1;;
    --skip-existing-output) SKIP_EXISTING_OUTPUT=1;;
    --skip-existing-jobs) SKIP_EXISTING_JOBS=1;;
    --output-dir) shift; OUTPUT_DIR=$1;;
    --input-dir) shift; INPUT_DIR=$1;;
    --submit-dir) shift; SUBMIT_DIR=$1;;
    --) shift; break;;
    *) echo "Unexpected option $1"; PrintUsage;;
  esac
  shift
done

if [ "$#" -ne 3 ]; then PrintUsage; fi


# Check for some required utilities
for exe in scramv1 condor_submit cmsRun.sh realpath; do
  if ! which $exe >& /dev/null; then
    echo "Cannot find $exe in PATH.  Your environment is not correctly set up."
    exit 1
  fi
done

# Additional command-line arguments

jobName=$1
CMSSW_HOME=`realpath $2`
configTemplate=`realpath $3`

# Now we have all the user's input.


runName=`basename $configTemplate .cfg`

OUTPUT_DIR=${OUTPUT_DIR:-${SRM_HOME}/$jobName-$runName}
INPUT_DIR=${INPUT_DIR:-${DCAP_HOME}/$jobName}
SUBMIT_DIR=${SUBMIT_DIR:-${SUBMIT_HOME}/$jobName-$runName}

#Strip off dcap://hostname:22125 to get raw pnfs path.
LOCAL_INPUT_DIR=${INPUT_DIR#dcap://*:22125}

#Get the part of INPUT_DIR that was stripped off.
INPUT_BASE=${INPUT_DIR%$LOCAL_INPUT_DIR}

if ! [ -d "$LOCAL_INPUT_DIR" ]; then
  echo "Error: No such input directory: $LOCAL_INPUT_DIR"
  exit 1
fi

if ! [ -d "$CMSSW_HOME" ]; then
  echo "Error: No such CMSSW directory: $CMSSW_HOME"
  exit 1
fi

if [ -d "$SUBMIT_DIR" ] && [ "$SKIP_EXISTING_JOBS" != "1" ]; then
  echo "Error: Submit directory already exists: $SUBMIT_DIR"
  echo "You must either remove it, or specify --skip-existing-jobs, or"
  echo "specify a different submission directory with --submit-dir"
  exit 1
fi

# Check the config template

for macro in \$inputFileName \$outputFileName; do
  if ! grep -F -q $macro $configTemplate; then
    echo "$macro must appear on the configuration template.  I can't find it in $configTemplate"
    exit 1
  fi
done

#
# CMSSW environment setup
#
originalDir=`pwd`
PATH=$PATH:$originalDir
export PATH
cd $CMSSW_HOME || die "Failed to cd to $CMSSW_HOME."
eval `scramv1 runtime -sh`

if [ "$?" != "0" ]; then
  echo "Failed to initialize CMSSW environment with scram in $CMSSW_HOME."
  exit 1
fi

runDir=$SUBMIT_DIR
submitFile=$runDir/submit

# Make sure submitFile name is unique in case we are continuing a previous
# submission.
if [ -f $submitFile ]; then
  num=1
  while [ -f $submitFile.$num ]; do
    num=$(($num+1))
  done
  submitFile=$submitFile.$num
fi


mkdir -p $runDir

cd $runDir || die "Failed to create directory $runDir"

#
# Job specification
#
Executable=`which cmsRun.sh`

# First put all the submit file commands that are the same for all jobs.
    cat <<EOF > $submitFile
X509UserProxy        = /tmp/x509up_u$UID
Universe             = vanilla
Executable           = $Executable
GetEnv               = true
Copy_To_Spool        = false
Notification         = never
WhenToTransferOutput = On_Exit
on_exit_remove       = (ExitBySignal == FALSE && ExitStatus == 0)
+IsFastQueueJob      = True
Requirements = TARGET.HasAFS =?= True
EOF


echo "Generating submit files in $runDir..."

#
# Loop over input files
#
count=0
find $LOCAL_INPUT_DIR -name \*.root |
while read inputFile
do
    inputFileURL=${INPUT_BASE}$inputFile

#
# Name the files
#
    jobtag=$runName-`basename $inputFile .root`
    consub=$jobtag.sub
    conlog=$jobtag.log
    stdout=$jobtag.out
    stderr=$jobtag.err
    jobcfg=$jobtag.cfg
    inputFileName=$inputFileURL
    outputFileName=$jobtag.root

#
# Create and set to the job subdirectory
#

    cd $runDir || die "Failed to cd to $runDir"


    if [ "$SKIP_EXISTING_JOBS" = "1" ] && [ -d $jobtag ]; then
      continue
    fi

    if [ "$SKIP_EXISTING_OUTPUT" = "1" ]; then
      # Check for existing output file
      if outputFileExists $OUTPUT_DIR/$outputFileName; then
        continue
      fi
    fi

    count=$(($count+1))
    if [ ! -z $JOB_LIMIT ] && [ $count -gt $JOB_LIMIT ]; then
        echo "Job limit $JOB_LIMIT reached.  Halting creation of jobs."
        break
    fi
    echo -n "."

    mkdir -p $jobtag
    cd $jobtag || die "Failed to cd to $jobtag"

#
# Prepare job configuration file
#

sed < $configTemplate \
    "s|\\\$inputFileName|$inputFileName|g;
     s|\\\$outputFileName|$outputFileName|g" > $jobcfg

#
# Prepare condor submit file for the job
#
cat >> $submitFile <<EOF

InitialDir           = $jobtag
Arguments            = $jobcfg `basename $outputFileName` $OUTPUT_DIR
Transfer_Input_Files = $jobcfg
output               = $stdout
error                = $stderr
Log                  = $conlog
Queue
EOF
done || exit 1

echo ""

cd $runDir

#
# Submit the job
#
if ! grep -q ^Queue $submitFile; then
  echo "No jobs were created, so there is nothing to do."
  rm $submitFile
  exit 0
elif [ -z "$NO_SUBMIT" ]; then
  condor_submit $submitFile || die "Failed to submit $submitFile"
else
  echo "Submit file $submitFile has been created but not submitted."
fi

echo -n "Jobs for $jobName are created in "
pwd
cd $originalDir
